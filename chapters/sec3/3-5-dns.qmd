# Things that only matter on the internet (DNS, HTTPS)  {#sec-dns-ssl}

In [Chapter @sec-networks-1] you learned all about how IP addresses are
where a resource lives on a computer network. But you've been using the
internet for a long time and you've rarely -- if ever -- actually used
an IP address. What gives?

IP addresses are hard to remember. And worse, they can change when
servers are replaced or changed.

To make the internet a little more human-friendly, the creators of the
internet built a system called the *domain name system* (DNS) that
translates human-readable domains, like $google.com$ to the IP addresses
where the resources actually are.

Sometimes you'll see a lot more than just a bare domain like google.com.
Sometimes you'll go to a website that looks something like this:

$$
\overbrace{https://}^{\text{Protocol}}\overbrace{\underbrace{blog}_{\text{Subdomain}}.\underbrace{example}_{\text{Primary Domain}}.\underbrace{com}_{\text{Top-Level Domain}}}^{\text{Domain}}/\overbrace{engineering}^{\text{Path}}
$$

There are a few other things that often pop up in URLs. The first is a
subdomain. For example, let's say I want to go to google maps. That's
available at maps.google.com, or my google drive at drive.google.com.

In these URLs, `maps` or `drive` are called subdomains. They're sites
below the main domain that have a distinct purpose. If you control a
domain, you also have ownership over all the subdomains in that domain.

## What happened to www?

When the internet was first started, it seemed quite important to
differentiate the address where a website would live from, for example,
the email domain people at that organization would use.

The `www` subdomain, short for *world wide web*, was invented as a way
to differentiate the website.

These days, the `www` subdomain is still technically a subdomain of the
main domain, but it is convention to make sure that the `www` subdomain
and the bare domain go to the same place. More on how to do that in the
lab.

You can also have resources other the root at `/`. For example, on my
personal website, \$alexkgold.space\$, the about me page is at
$alexkgold.space/about$. You also control all paths below a domain when
you control the domain.

The question of whether to host things on subdomains or paths is well
beyond the scope of this book, but generally paths are things that are
properly "below" whatever's at the bare domain and subdomains are often
entirely different entities. But that's just a matter of style and SEO.

::: callout-note
You can get the

An IP address really is the address of the resource. You can get the IP
address of $google.com$ using the terminal command `nslookup`.

At the time of this writing, one of the addresses that comes back is
`172.253.115.102`. Assuming that address is still valid, you can just
put that into your browser's search bar and get right to $google.com$.

But that's not usually what we do. Instead, we use $google.com$ to get
to google. What gives?
:::

If you think back to how a packet gets to where it's going, we talked
about how the packet gets routed to successively higher-level routers
until a router knows where the packet is going and sends it back down.
It turns out that this process is actually repeated *twice* -- once to
lookup the IP address for the domain, and then to actually send the
information.

The details of translating a domain into an IP address are quite
intricate, but the upshot of this process -- called *DNS resolution* --
is that your computer asks for the IP address of the domain you put in,
and that query is routed to successively higher levels of DNS servers
until it finds one that knows the IP address for the domain you're
trying to reach.

There are two components to a domain, the *domain name* and the *top
level domain*. A domain maps to an IP address. Many domains can map to
one IP address, so you'll notice that you can access google at either
$google.com$ or $google.net$.

::: callout-note
## An aside about top-level domains

The top level domain is whatever appears after the `.`. The internet was
created with only a handful of top level domains -- `.com`, `.net`, and
`.org` were some of the first.

Mmore were opened up over time. In 2013 ICANN -- the group that controls
how domains are assigned -- decided to allow people to register their
own top level domains. That's why there's been an explosion in websites
at top level domains like `.io`, `.ai`, and `.fun` in the last decade or
so.

If you, like me, think it'd be fun to have your own top level domain,
they are unfortunately not for normal humans. In 2012, the initial
application fee was \$185,000.
:::

### Learning to Hate DNS

As you get deeper into using servers, you will learn to hate DNS with a
fiery passion. While it's necessary so we're not running around trying
to remember incomprehensible IP addresses, it's also very hard to debug
as a server admin.

Let's say I've got the public domain `example.com`, and I'm taking down
the server and putting up a new one. I've got to alter the public DNS
record so that everyone going to `example.com` gets routed to the new IP
address, and not the old one.

The thing that makes it particularly challenging is that the DNS system
is highly decentralized. There are thousands of public DNS servers that
a request could get routed to, and many of them may need updating.

Moreover, the simplified description I gave of DNS left one important
thing out -- when your computer or an intermediate DNS server looks up
an IP address for you, it caches it. This is because its likely that if
you've looked up a domain once, you're going to do it again soon. This
is great if you are *using* the internet and don't want to wait for DNS
lookups, but when you're changing the domains on servers you control, it
means you need to wait for caches to expire for changes to propagate.

Depending on the changes you're making, those changes can take up to 24
hours to propagate. After you make a change, if it's not working, you're
left in a guessing game of whether you made a mistake or it just hasn't
propagated yet. It's very annoying.

Sometimes, trying a private browsing window will sidestep DNS and other
sorts of caches, but not always.

## Troubleshooting networking

Networking can be difficult to manage because there are many places it
can go awry. Let's say you've configured a service on your server, but
you just can't seem to access it.

The first thing you'll want to check is whether it's a networking issue.

The `ping` command can be useful for checking whether your server is
reachable on the network. For example, here's what happens when I `ping`
the domain where this book sits.

    > ping -o do4ds.com                                                                            

    PING do4ds.com (185.199.110.153): 56 data bytes
    64 bytes from 185.199.110.153: icmp_seq=0 ttl=57 time=13.766 ms

    --- do4ds.com ping statistics ---
    1 packets transmitted, 1 packets received, 0.0% packet loss
    round-trip min/avg/max/stddev = 13.766/13.766/13.766/0.000 ms

This looks great -- it sent 1 packet to the server and got one back.
That's exactly what I want. Seeing an unreachable host or packet loss
would be an indication that my networking probably isn't configured
correctly somewhere between me and the server. I generally like to use
`ping` with the `-o` option for sending just **o**ne packet -- as
opposed to continuously trying.

If `ping` succeeds but I still can't access the server, `curl` is good
to check. `curl` actually attempts to fetch the website at a particular
URL. At this point, I'm

A simple way to check for a networking issue is with the `curl` command.
`curl` attempts to reach a listening service at the URL specified and
return what it finds. It's often useful to use `curl` with the `-I`
option so it just returns a simple status report, not the full contents
of what it finds there.

For example, here's what I get when I `curl` CRAN from my machine.

     > curl https://cran.r-project.org/ -I                                                         
     
    HTTP/1.1 200 OK
    Date: Sun, 15 Jan 2023 15:34:19 GMT
    Server: Apache
    Last-Modified: Mon, 14 Nov 2022 17:33:06 GMT
    ETag: "35a-5ed71a1e393e7"
    Accept-Ranges: bytes
    Content-Length: 858
    Vary: Accept-Encoding
    Content-Type: text/html

The important thing here is that first line. The server is returning a
`200` HTTP status code, which means all is well. For more on HTTP status
codes and how to interpret them, see [Chapter @sec-networks-1].

There are a lot of reasons you might not get a `200` return. The main
thing you'll want to check from within the server is that your service
is actually up and running on the port you think it is.

## Comprehension Questions

1.  Write down the step-by-step procedure that is followed when you sit
    down at your laptop and type google.com into the search bar. Your
    explanation should include the following terms: URL, domain, DNS,
    protocol, HTTP, HTTPS, Default Address, Router
2.  Create a mind map of the following terms: Application Layer
    Protocol, HTTP, HTTPS, SSH, Port, 22, 80, 443
3.  In the following URLs, what are the domain, top-level domain, path,
    subdomain, query parameters?
    1.  https://blog.example.com/2022-10-30

    2.  facebook.com?search=alex.gold

    3.  https://alexkgold.space/mfy.html
4.  Write a mind map of the following terms: HTTP, HTTPS, SSL, TLS, CA,
    Public Certificate, Private Certificate, 443

## Lab: Getting a domain and SSL for your server

In this lab, we're going to go from having to SSH tunnel to be able to
use your data science workbench to making it available over the internet
in general. That means we're going to have to do 3 things: configure the
networking to allow HTTP traffic, configure a real domain for our
server, and configure SSL to keep our traffic safe.

We know that right now our RStudio Server is ready to serve traffic
inside our server on port 8787 and JupyterHub is on 8000, but nothing
can get to them! So the first step is to allow traffic to get to them.

Obviously, the easiest thing we could do would be to just open up ports
8787 and 8000 to the world. This works! If you want to try it, go to the
settings for your server's security group and just add a custom TCP rule
allowing access to ports 8787 and 8000 from anywhere. If you visit
\<server address\>:8787 you should get RStudio (login with `test-user`
and your password) and if you visit 8000, you can get to Jupyter.

It works!

BUT now your users have to remember these arbitrary ports to use your
server. It's also insecure. There isn't a good way to secure these ports
with SSL.[^3-5-dns-1]

[^3-5-dns-1]: As of this writing, JupyterHub supports configuring SSL in
    the product, but RStudio Server does not. Posit Workbench, the paid
    version of RStudio Server does support SSL configuration.

So we're going to put a proxy in front of our two editors that will
allow people to go to either RStudio or Jupyter on subpaths.

There are two popular open source options for proxies -- nginx and
apache. We're going to use nginx. Configuring nginx is generally a
pretty painful experience -- it's a matter of making sure there are no
typos, and debugging can be rather difficult. Until you get really
comfortable with proxies, you'll probably mostly just copy/paste config
lines in. That's what we're going to do here.

Here are the steps:

1.  Install nginx with `sudo apt install nginx`.
2.  Save a copy of `nginx.conf`,
    `cp /etc/nginx/nginx.conf /etc/nginx/nginx-default.conf`.
3.  Replace the `http` block in the default nginx.conf with the
    following. Put the following into the config
    `sudo vim /etc/nginx/nginx.conf`.
4.  Test that your configuration is valid `sudo nginx -t`.
5.  Start nginx `sudo systemctl start nginx`. If you see nothing all is
    well.

If you need to change anything, update the config and then restart with
`sudo systemctl restart nginx`.

QUESTION - is this too complicated? Should I make it an either/or and
then allow people to do both as a challenge?

``` {filename="/etc/nginx/nginx.conf"}
http {
  
  \# Enable websockets (needed for Shiny)
  map \$http_upgrade \$connection_upgrade { 
    default upgrade; '' close; 
  }
  
  server { listen 80;
    
    location /rstudio/ {
      # Needed only for a custom path prefix of /rstudio
      rewrite ^/rstudio/(.*)$ /$1 break;
      
      # Use http here when ssl-enabled=0 is set in rserver.conf
      proxy_pass http://localhost:8787;
      
      proxy_http_version 1.1;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection $connection_upgrade;
      proxy_read_timeout 20d;
      
      # Not needed if www-root-path is set in rserver.conf
      proxy_set_header X-RStudio-Root-Path /rstudio;
      
      # Optionally, use an explicit hostname and omit the port if using 80/443
      proxy_set_header Host $host:$server_port;
    }
    
    location /jupyter/ {
      # NOTE important to also set base url of jupyterhub to /jupyter in its config
      proxy_pass http://127.0.0a.1:8000;
      
      proxy_redirect   off;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header Host $host;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
      
      # websocket headers
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection $connection_upgrade;
    }
  }
```

There's one more thing you'll have to do, which is to let RStudio and
JupyterHub know that they're on a subpath. Complex web experences like
RStudio and JupyterHub frequently send people to a different subpath
internally. In order to do so properly, they need to know to prepend all
of those requests with the subpath.

RStudio accepts a header from the proxy that lets it know what path it's
on (see the `X-RStudio-Root-Path` header line in the nginx config).
Jupyter needs to be explicitly told.

First we'll need to get to the autogenerated config with

     jupyterhub --generate-config
     sudo mkdir /etc/jupyterhub
     sudo mv jupyterhub_config.py /etc/jupyterhub

Find the line you want to change -- you can search in vim with
`/ <thing you're searching for>`. Go to the next hit with `n`.

When you get to the line that reads
`# c.JupyterHub.bind_url = 'http://:8000'`, uncomment and add a
`/jupyter` on the end, so it reads
`c.JupyterHub.bind_url = 'http://:8000/jupyter`.

Start jupyterhub with a specific config file.

jupyterhub -f /etc/jupyterhub/jupyterhub_config.py

### How to configure DNS for your server

From the perspective of someone trying to set up their own website,
there's only one DNS server that matters to you personally -- the DNS
server for your *domain name registrar*.

Domain name registrars are the companies that actually own domains. You
can buy or rent one from them in order to have a domain on the internet.
So let's say you take the data science server you set up in lab 1 and
decide that you want to host it at a real domain.

Your first stop would be a domain name registrar where you'd find an
available domain you like and pull out your credit card.

Costs for domain names vary widely. Buying a meaningless domain in a
less popular top-level domain, say `ladskfmlsdf.me` can cost as little
as \$3 per year. On the other hand, buying a `.com` domain that's a real
word or phrase can be a few thousand dollars -- and there are articles
every few years about some major company accidentally allowing their
domain name to lapse and ransoming it back for stupid amounts of money.

So, conceptually, it's easy to understand how a domain comes to stand in
for an IP address, with DNS being the directory that ties the two
together.

The harder part is the nitty gritty of how you accomplish that mapping
yourself, which we'll get into now.

Configuration of DNS is done by way of *records*, of which there are a
menagerie of types you *can* configure. Luckily, most simple
configurations only need *CNAME* and *A* records.

Here's an imaginary DNS record table for the domain `example.com`:

| Path/Host | Type  | Target         |
|-----------|-------|----------------|
| `@`       | A     | `143.122.8.32` |
| `www`     | CNAME | example.com    |
| `*`       | A     | `143.122.8.33` |

Let's go through how to read this table.

Since we're configuring `example.com`, the paths/hosts in this table are
relative to `example.com`.

In the first row we're configuring an A record to go to the target IP
address. *A records* (or their IPv6 cousin *AAAA records*) map a domain
to an actual IP address. The path `@` is a special symbol meaning exact
match. So by this configuration, any traffic to `example.com` will be
passed straight through to the specified IP address.

The second row deals with traffic to the `www` subdomain. *CNAME
records* alias sub-domains. They're most frequently used to map
sub-domains to the main domain. Since this is a `CNAME` record for
example.com, this record indicates that traffic to www.example.com
should be treated exactly like traffic to `example.com`. Some domain
providers do automatic redirection of `www` traffic, and so this row may
not be necessary in some configurations.

The last record uses the wildcard symbol `*` to send all subdomain
traffic that's not already spoken for -- say `blog.example.com` or
`info.example.com` directly to the IP address specified. In this case,
I'm sending all of those subdomains to a different IP address, maybe a
404 (not found) page -- or maybe I'm serving all the subdomains off a
different server.

So what happens is that your query goes through several layers of public
DNS servers to get to the DNS entry for your domain name registrar. In
many cases, you'll directly configure your domain name registrar to
point to your website or server -- but you also can configure the domain
name registrar to point at another set of DNS servers you actually
control with an *NS record*.

If you're setting up your own server, this probably isn't the case, but
some large enterprises do run their own private DNS servers.

#### Actually Doing It

Allocate an Elastic IP. If you've restarted your server, you've probably
noticed that the IP address changed! This can be a real pain if you have
to reconfigure your DNS every time. AWS offers a service called Elastic
IP that gives you an IP address that won't change that you can use with
your instance, even if you restart it.

As of this writing, Elastic IPs are free as long as it's associated with
a single running EC2 instance. You get charged if they're not active --
basically AWS doesn't want you hoarding Elastic IPs. Great -- just make
sure to give back the elastic IP if you take down your instance.

::: callout-note If you were doing this for real, and not in a somewhat
arbitrary order that's grouped by topic, it would've made sense to set
up the elastic IP as soon as you brought the server up so you only
would've used that IP address. :::

    Go to Elastic IP and click allocate. Once it has been allocated, you'll need to associate it with the existing Instance you created. Choose the instance and the default private IP address.

I was given the Elastic IP `52.70.205.182`. So now if I go to
`52.70.205.182`, I get my server.

Note that once you make this change, your server will no longer be
available at its old IP address, so you'll have to ssh in at the new
one. If you have SSH terminals open when you make the change, they will
break.

This part will not be free, but it can be very cheap. You'll have to
actually buy a domain name. The easiest way to do this is via AWS's
Route53 service. You can get domains on Route53 for as little as \$9 per
year. But there are cheaper services. For example, I was able to get the
domain do4ds-lab.shop for \$1.98 for a year on namecheap.com.

Once you've got your domain, you have to configure your DNS. You'll have
to create 2 A records -- one each for the \@ host and the \* host
pointing to your IP and one for the CNAME at the www with the value
being your bare domain.

So in NameCheap, my Advanced DNS configuration looks like this:

    ![](images-traffic/namecheap-config.png)

Now you just have to be patient. Unfortunately DNS takes time to
propagate. After a few minutes, your server should be reachable at your
domain. Wow!
