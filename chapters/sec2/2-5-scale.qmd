# Server Resources and Scaling {#sec-scale}

If your server is for more than just playing, you will need to make sure
you've got sufficient computational resources. That means appropriately
sizing and scaling your server to accommodate your work.

This chapter is going to help you develop a mental model of what a
server's computational resources are, teach you about the command line
tools to assess resource usage, and provide recommendations on how to
scale and size a server for data science.

## The briefest intro to computational theory

You're probably aware that everything you've ever seen on a computer --
from this book to your work in R or Python, your favorite internet cat
videos, and Minecraft -- is just 1s and 0s.

But the 1s and 0s aren't actually the interesting part. They are just
binary representations of integers (whole numbers). The mind bending
part is that the integers represent something meaningful and **the
only** thing the computer does is add these integers.[^2-5-scale-1]

[^2-5-scale-1]: This was proved in Alan Turing's 1936 paper on
    computability. If you're interested in learning more, I recommend
    [The Annotated Turing: A Guided Tour Through Alan Turing's Historic
    Paper on Computability and the Turing
    Machine](https://www.goodreads.com/en/book/show/2333956.The_Annotated_Turing)
    by Charles Petzold for a surprisingly readable walkthrough.

That means that a helpful mental model for a computer is factory for
doing addition problems. Everything you ask your computer to do is
turned into an addition problem, then processed and returned, with the
results interpreted as meaningful.

Since a computer is like an addition factory, decisions about server
sizing and scaling are akin to questions of how to optimally design the
conveyor belts in a factory. In this computer as factory analogy, there
are three main resources you should consider -- compute, memory, and
storage.

## How computers compute

The addition assembly line itself -- where the work gets done -- is
referred to as *compute*. It's where $2+2$ gets turned into $4$, and
where $345619912 + 182347910$ gets turned into $527967822$.

All computers do their main compute in their central processing unit
(CPU), which completes addition problems in one or more *cores*.

The speed of the CPU is largely determined by the number of cores and
the speed of those cores.

The *number of cores* is like the number of lines in the factory. These
days, most consumer-grade laptops have between 4 and 16 physical cores.
Many have software capabilities that effectively double that number, so
they can do between 4 and 32 addition problems simultaneously.

*Single core clock speed*, how quickly a single addition problem is
completed by a single core, is the baseline speed of an individual core.
You can think of this as how fast the conveyor belt moves. Clock speeds
are measured in operations per second or *hertz (hz)*. The cores in your
laptop probably max out between two and five *gigahertz (GHz)*, which
means between two billion and five billion operations per second.

For decades, many of the innovations in computing came from increases in
single core clock speed, but those have fallen off in the last few
decades. The clock speeds of consumer-grade chips increased by
approximately 10x during the 90s, by 2-3x in the 2000s, and somewhere
between not at all and 1.5x in the 2010s.

But computers have continued getting a lot faster even as the increase
in clock speeds has slowed. The increase has mostly come from increases
in the number of cores, better software usage of parallelization, and
faster loading and unloading of the CPU (called the *bus*).

## Recommendation 1: Fewer, faster CPU cores

R and Python are single-threaded. This means that unless you're using
special libraries for parallel processing, you'll end up redlining a
single CPU core while the others sit unused.

Therefore, for most R and Python work, single core clock speed matters
more than the number of cores, and fewer, faster cores are usually
preferable to many slower ones.

You're probably not used to thinking about this tradeoff from buying a
laptop or phone. The reality is that modern CPUs are pretty darn good
and you should just buy the one that fits your budget.

If you're standing up a cloud server, you often do have an explicit
choice between more slower cores and fewer faster ones, determined by
the instance family.

If you're running a multi-user server, the number of cores you need can
be hard to estimate. If you're doing non-ML tasks like counts and
dashboarding or relatively light-duty machine learning, I might advise
the following:

$$
\text{n cores} = \text{1 core per user} + 1
$$

The spare core is for the server to do its own operations apart from the
data science usage. On the other hand, if you're doing heavy-duty
machine learning or parallelizing jobs across the CPU, you may need more
cores than this rule of thumb.

## How memory works

Your computer's random access memory (RAM) is its short term storage.
You can think of RAM as the area adjacent to the assembly line where
work to be done sits waiting and completed work is temporarily placed
before it gets sent somewhere else.

Your computer can access things in RAM very quickly, so things stored in
RAM are ready to go. The downside is that RAM is temporary. When your
computer turns off, the RAM gets wiped.[^2-5-scale-2]

[^2-5-scale-2]: You probably don't experience this. Modern computers are
    pretty smart about dumping RAM onto the hard disk before shutting
    down and bringing it back on startup, so you usually won't notice
    this happening.

::: callout-note
Memory and storage are measured in *bytes* with metric prefixes.

Common sizes for memory these days are in *gigabytes* (billion bytes)
and *terrabytes* (trillion bytes). Some enterprise data stores run on
the scales of thousands of terrabytes (*pettabytes*) or even thousands
of pettabytes (*yottabytes*).
:::

Modern consumer-grade laptops come with somewhere between 4 and 16 Gb of
memory.

## Recommendation 2: Get as much RAM as feasible

In most cases, R and Python have to load all of your data into memory.
Thus, the size of the data you can use is limited to the size of your
machine's RAM.

Most other machine limits will result in work completing slower than you
might like, but trying to load too much data into memory will make your
session crash.

::: callout-note
If you're running into this limitation, go back and think about your
project architecture as discussed in [Chapter @sec-proj-arch]. Maybe you
can load less data into memory.
:::

Because your computer needs memory for things other than R and Python,
and because you'll often be doing transformations that temporarily
increase the size of your data, you need more memory than your largest
data set.

Nobody has ever complained about having too much RAM, but a good rule of
thumb is that you'll be happy if:

$$\text{Amount of RAM} \ge 3 * \text{max amount of data}$$

If you're thinking about running a multi-user server, you'll need to
take a step back to think about how many concurrent users you expect and
how much data you anticipate each one to load.

## Understanding storage

*Storage*, or *hard disk/drive*, is where your computer stores things
for the long term. It's where applications are installed and where you
save things you want to keep.

Relative to the RAM that's right next to the factory floor, your
computer's storage is like the warehouse in the next building. Storage
is much slower than RAM, often somewhere between 10x to 100x, but
storage allows you to save things permanently.

Storage was even slower until a few years ago when *solid-state drives
(SSDs)* became common. SSDs are collections of flash memory chips that
are up to 15x faster than the *hard disk drives (HDDs)* that preceded
them.

HDDs consist of spinning magnetic disks with magnetized read/write heads
that save and read data from the disks. While HDDs spin very fast --
5,400 and 7,200 RPM are common speeds -- SSDs with no moving parts are
much faster.

## Recommendation 3: Get lots of storage, it's cheap

When it comes to configuring storage on your server, you should get a
lot, but don't spend a lot of time looking for the perfect solution
since it's cheap and easy to upgrade. In fact, it's almost always more
cost effective to buy additional storage when needed rather than have an
expensive professional spend their time trying to figuring out how to
move things around.

::: callout-note
If the IT/Admins at your organization want you to spend a lot of time
deleting things from storage, that's usually a red flag that they aren't
thinking much about how to make the overall organization work more
smoothly.
:::

If you're running a multi-user server, the amount of storage you need
depends a lot on your data and your workflows. If you're not saving
large data files, the amount of space each person needs on the server is
small. Code is very small and it's rare to see R and Python packages
take up more than a few dozen Mb per data scientist. A reasonable rule
of thumb is to choose

$$
\text{Amount of Storage} = \text{1Gb} * \text{n users}
$$

On the other hand, if you will be saving a lot of data, you've got to
take that into account. In some organizations, each data scientist will
save dozens of flat files of a Gb or more for each of their projects.

::: callout-note
If you're working with a professional IT admin, they may be concerned
about the storage implications of having package copies for each person
on their team, a best practice for using environments as code as
discussed in [Chapter @sec-env-as-code]. I've heard this concern a lot
from IT/Admins thinking ahead about running their server and almost
never of a case where it's actually been a problem in the end.
:::

If you're operating in the cloud, this really isn't an important choice.
As you'll see in the lab, upgrading the amount of storage you have is a
trivial operation, requiring at most a few minutes of downtime. Choose a
size you estimate will be adequate and add more if needed.

## GPUs are special-purpose compute

All computers have a CPU. Some computers have specialized chips where
the CPU can offload particular tasks -- the most common being the
graphical processing unit (GPU). GPUs are architected for tasks like
editing photos or videos, rendering video game graphics, some kinds of
machine learning, and, yes, Bitcoin mining.[^2-5-scale-3]

[^2-5-scale-3]: Purpose-built chips are becoming more common for AI/ML
    tasks, especially doing local inference on large models. These
    include Tensor Processing Units (TPUs) and Intelligence Processing
    Units (IPUs).

A GPU is an addition factory just like a CPU, but with the opposite
architecture. CPUs have only a handful of cores, but those cores are
fast. A GPU takes the opposite approach with many (relatively) slow
cores.

Where a consumer-grade CPU has 4-16 cores, mid-range GPUs have 700-4,000
cores, with each one running at only about 1% to 10% the single core
clock speed of a CPU core. For the tasks GPUs are good at, the
overwhelming parallelism ends up being more important than the speed of
any individual core, and GPU computation can be dramatically faster.

The choice of whether you need a GPU to do your work will really depend
on what you're doing and your budget.

## Recommendation 4: Get a GPU, maybe

The tasks that most benefit from GPU computing include training highly
parallel machine learning models like deep learning or tree-based
models. If you do have one of these use cases, GPU computing can
massively speed up your computation -- making models trainable in hours
instead of days.

If you are planning to use cloud resources for your computing,
GPU-backed instances are quite pricey (hundreds of dollars an hour as of
this writing). You'll want to be careful about only putting those
machines up when you're using them.

Because GPUs are expensive, I generally wouldn't bother with GPU-backed
computing unless you've already tried without and find that it takes too
long to be feasible.

It's also worth noting that using a GPU won't happen automatically. The
tooling has gotten good enough that it's usually easy to set up, but
your computer won't train your XGBoost models on your GPU unless you
tell it to do so.

Now that you're equipped with some general recommendations about
choosing the right amount of resources, let's get into how to tell
whether it might be time to upgrade a system you already have.

## Assessing RAM + CPU usage

Once you've chosen your server size and gotten up and running, you'll
want to be able to monitor RAM and CPU for problems.

A running program is running is called a *process*. For example, when
you type `python` on the command line to open a REPL, that starts a
single Python process. If you were to start a second terminal session
and run `python` again, you'd have a second Python process.

Complicated programs often involve multiple interlocking processes. For
example, running the RStudio IDE involves (at minimum) one process for
the IDE itself and one for the R session that it uses in the background.
The relationships between these different processes are mostly hidden
from you -- the end user.

As an admin, you may want to inspect the processes running on your
system at any given time. The `top` command is a good first stop. `top`
shows the top CPU-consuming processes in real time along with a number
of other facts about them.

Here's the `top` output from my machine as I write this sentence.

``` {.bash filename="Terminal"}
PID    COMMAND      %CPU TIME     #TH    #WQ  #PORT MEM    PURG   CMPRS PGRP
0      kernel_task  16.1 03:56:53 530/10 0    0     2272K  0B     0B    0
16329  WindowServer 16.0 01:53:20 23     6    3717  941M-  16M+   124M  16329
24484  iTerm2       11.3 00:38.20 5      2    266-  71M-   128K   18M-  24484
29519  top          9.7  00:04.30 1/1    0    36    9729K  0B     0B    29519
16795  Magnet       3.1  00:39.16 3      1    206   82M    0B     39M   16795
16934  Arc          1.8  18:18.49 45     6    938   310M   144K   61M   16934
```

In most instances, the first three columns are the most useful. The
first column is the unique process id (`pid`) for that process. You've
got the name of the process (`COMMAND`) and how much CPU it's using.
You've also got the amount of memory used a few columns over. Right now,
nothing is using a lot of CPU.

The `top` command takes over your whole terminal. You can exit with
`Ctrl + c`.

::: callout-note
## So much CPU?

For `top` (and most other commands), CPU is expressed as a percent of
*single core* availability. On a modern machine with multiple cores,
it's very common to see CPU totals well over 100%. Seeing a single
process using over 100% of CPU is rare.
:::

Another useful command for finding runaway processes is `ps aux`. It
lists a snapshot of all processes running on the system, along with how
much CPU or RAM they're using. You can sort the output with the `--sort`
flag and specify sorting by cpu with `--sort -%cpu` or by memory with
`--sort -%mem`.

Because `ps aux` returns *every* running process on the system, you'll
probably want to pipe the output into `head`. In addition to CPU and
Memory usage, `ps aux` tells you who launched the command and the PID.

One of the times you'll be most interested in the output of `top` or
`ps aux` is when something is going rogue on your system and using more
resources than you intended. If you have some sense of the name or who
started it, you may want to pipe the output of `ps aux` into `grep` to
find the `pid`.

For example, I might run `ps aux | grep RStudio` to get[^2-5-scale-4]

[^2-5-scale-4]: I've done a bunch of doctoring to the output to make it
    easier to read.

``` {.bash filename="Terminal"}
> ps aux | grep RStudio
USER      PID   %CPU %MEM STARTED TIME     COMMAND
alexkgold 23583 0.9  1.7  Sat09AM 17:15.27 /Applications/RStudio.app/RStudio
alexkgold 23605 0.5  0.4  Sat09AM  1:58.16 /Applications/RStudio.app/rsession
```

RStudio is behaving nicely on my machine, but if it were not responsive,
I could make note of its `pid` and end the process immediately by
calling the `kill` command with the `pid`.

## Examining at storage usage

A common culprit for weird server behavior is running out of storage
space. There are two handy commands for monitoring the amount of storage
you've got: `du` and `df`. These commands are almost always used with
the `-h` flag to put file sizes in human-readable formats.

`df` (disk free) shows the capacity left on the device where the
directory sits. For example, here's the result of running the `df`
command on the chapters directory on my laptop that includes this
chapter.

``` {.bash filename="Terminal"}
> df -h chapters
Filesystem     Size   Used  Avail Capacity iused      ifree %iused  Mounted on
/dev/disk3s5  926Gi  227Gi  686Gi    25% 1496100 7188673280    0%   /System/Volumes/Data
```

You can see that the `chapters` folder lives on a disk called
`/dev/disk3s5` that's a little less than 1Tb and is 25% full -- no
problem. On a server, this can be really useful to know because it's
quite easy to switch a disk out for a bigger one in the same spot.

If you've figured out that a disk is full, it's usually most cost
effective to just buy a bigger disk. But sometimes something weird
happens. Maybe there are a few exceptionally big files, or you think
unnecessary copies are being made.

If so, the `du` command (disk usage) gives you the size of individual
files inside a directory. It's particularly useful in combination with
the sort command. For example, here's the result of running `du` on the
chapters directory where the text files for this book live.

``` {.bash filename="Terminal"}
> du -h chapters | sort
12M chapters
1.7M    chapters/sec1/images
1.8M    chapters/sec1
236K    chapters/images
488K    chapters/sec2/images-traffic
5.3M    chapters/sec2/images-networking
552K    chapters/sec2/images
6.6M    chapters/sec2
892K    chapters/append/images
948K    chapters/append
```

If I were thinking about cleaning up this directory, I could see that my
`sec1/images` directory is my biggest single directory. If you find
yourself needing to find big files on your Linux server, it's worth
spending some time looking through the useful options in the help pages
for `du`.

## Running out of Resources

If you recognize that you're running out of resources on your current
server, you may want to move to something bigger. There are two primary
reasons servers run out of room.

The first is because people are running big jobs. This can happen at any
scale of organization. There are data science teams of one who have use
cases that necessitate terrabytes of data.

The second reason is because you have a lot of people using your server.
This is generally a feature of big data science teams, irrespective of
workload size.

Either way, there are two options for how to scale your data science
workbench. The first is *vertical scaling*, which is just a fancy way of
saying get a bigger server. The second option is *horizontal scaling*,
which means running a whole fleet of servers in parallel and spreading
the workload across them.

As a data scientist, you shouldn't be shy about vertically scaling if
your budget allows it. The complexity of managing a `t3.nano` with 2
cores and 0.5 Gb of memory is exactly the same as a `C5.24xlarge` with
96 cores and 192 Gb of memory. In fact, the bigger one may well be
easier to manage since you won't have to worry about running low on
resources.

There are limits to the capacity of vertical scaling. As of this
writing, AWS's general-use instance types max out at 96-128 cores. That
can quickly get eaten up by 50 data scientists with reasonably heavy
computational demands.

Once you're thinking about horizontal scaling, you've got a distributed
service problem on your hands, which is inherently difficult. You should
almost certainly get an IT/Admin professional involved. See [Chapter
@sec-ent-scale] for more on how to talk to them about it.

### AWS Instances for data science

AWS offers a variety of different EC2 instance types split up by
*family* and *size*. The family is the category of EC2 instance.
Different families of instances are optimized for different kinds of
workloads.

Here's a table of common instance types for data science purposes:

| Instance Type | What it is                                                            |
|------------------|------------------------------------------------------|
| `t3`          | The "standard" configuration. Relatively cheap. Sizes may be limited. |
| `C`           | CPU-optimized instances, aka faster CPUs                              |
| `R`           | Higher ratio of RAM to CPU                                            |
| `P`           | GPU instances, very expensive                                         |

Within each family, there are different sizes available, ranging from
*nano* to multiples of *xl*. Instances are denoted by
*\<family\>.\<size\>*. For example, when we put our instance originally
on a free tier machine, we put it on a `t2.micro`.

In most cases, going up a size doubles the amount of RAM, the number of
cores, and the hourly cost. You should do some quick math before you
stand up a `C5.24xlarge` or a GPU-based `P` instance. If your instance
won't be up for very long, it may be fine, but make sure you take it
down when you're done lest you rack up a huge bill.

## Comprehension Questions

1.  Think about the scenarios below. Which part of your computer would
    you want to upgrade to solve the problem?

    1.  You try to load a big csv file into pandas in Python. It churns
        for a while and then crashes.

    2.  You go to build a new ML model on your data. You'd like to
        re-train the model once a day, but it turns out training this
        model takes 26 hours on your laptop.

    3.  You design a visualization using the `{matplotlib}` package and
        want to create one version of the visualization for each US
        State. You could do it in a loop, but it would be faster to
        parallelize the plot creation. Right now you're running on a
        `t2.small` with 1 CPU.

2.  Draw a mind map of the following: CPU, RAM, Storage, Operations Per
    Second, Parallel Operations, GPU, Machine Learning

3.  What are the architectural differences between a CPU and a GPU? Why
    does this make a GPU particularly good for Machine Learning?

4.  How would you do the following:

    1.  Find all running Jupyter processes that belong to the user
        `alexkgold`.

    2.  Find the different disks attached to your server and see how
        full each one is.

    3.  Find the biggest files in each user's home directory.

## Lab: Changing Instance Size

In this lab, we're going to upgrade the size of our server. And the best
part is that we're in the cloud so it will only take a few minutes.

### Step 1: Confirm current server size

First, let's confirm what we've got available. Once you `ssh` into the
server, you can check the number of CPUs you've got with `lscpu` in a
terminal. Similarly, you can check the amount of RAM with `free -h`.
This is just so you can prove to yourself later that the instance really
changed.

### Step 2: Change the instance type and bring it back

Now, you can go to the instance page in the AWS console. The first step
is to stop (not terminate!) the instance. This means that changing
instance type *does* require some downtime, but it's quite limited.

Once the instance has stopped, you can change the instance type under
Actions \> Instance Settings. Then start the instance. It'll take a few
seconds to start the instance.

### Step 3: Confirm new server size

For example, I changed from a `t2.micro` to a `t2.small`. Both only have
1 CPU, so I won't see any difference in `lscpu`, but running `free -h`
before and after the switch reveals that I've got more RAM:

```         
test-user@ip-172-31-53-181:~$ free -h
               total        used        free      shared  buff/cache   available
Mem:           966Mi       412Mi       215Mi       0.0Ki       338Mi       404Mi
Swap:             0B          0B          0B
test-user@ip-172-31-53-181:~$ free -h
               total        used        free      shared  buff/cache   available
Mem:           1.9Gi       225Mi       1.3Gi       0.0Ki       447Mi       1.6Gi
Swap:             0B          0B          0B
```

There's twice as much after the change!

There are some rules around being able to change from one instance type
to another, but this is a superpower if you've got variable workloads or
a team that's growing. Once you're done with your larger server, it's
just as easy to scale it back down.

### Step 4: Upgrade storage (maybe)

If you want more storage, it's similarly easy to resize the EBS volume
attached to your server.

I wouldn't recommend doing it for this lab because you can only
automatically adjust volume sizes up. That means you'd have to manually
transfer all of your data if you ever wanted to scale back down.

If you do resize the volume, you'll have to let Linux know so it can
resize the filesystem with the new space available. AWS has a great
walkthrough called *Extend a Linux filesystem after resizing the volume*
that I recommend you follow.
