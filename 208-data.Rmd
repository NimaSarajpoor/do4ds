# Choosing and Using A Data Architecture

* DataOps is a huge field -- a lot of it touches data science
* Some of the biggest consideration when you're thinking about data science

## Options for Data Storage

* 3 basic types of data stores: flat file (csv, pickle/rds), flat file w/ interactive read (arrow), database
* Implications how to configure access

* Database is standalone option, usually requires configuring separate server
* Other two can be configured two main ways:
  * File system
  * Bucket Storage
  
* Data Lake -- usually for raw data, basically bucket storage writ large, sometimes include interacticve read capabilities
* Data Warehouse -- usually a database

## How to pick
* Flat files are simplest
* Flat files w/ interactive read are great for med-large data
* Databases often already exist
* If not, a few tips:
  * SQL-based databases are the backbone of analytics work
  * Database as a service is a basic cloud provider
  * There are SO many options
  TODO: How much more in depth am I going here?

## Working with File Systems

* Working on your laptop file system isn't great
* Working in a cloud provider is different than on your laptop
  * Volumes are separate from compute
  * Often have automated snapshots/backups
  * Volumes can also be shared across multiple servers
* Process of putting a volume on a server is called mounting

## Working with Databases

* Two main ways to work with databases from R/Python - direct connection or w/ connector/driver (JDBC/ODBC)
* https://docs.google.com/presentation/d/1wJ3YnB4ob3AkNRDLpvYy3B-JMUaVsPjl3AA5QkN7fII/edit

### Security

Row-level security
Kerberos
JWT
IAM roles

## Exercises
1. Connect to and use an S3 bucket from the command line and from R/Python.
2. Stand up a container with Postgres in it, connect using isql, then from R/Python using ODBC/JDBC.
3. Stand up an EC2 instance w/ EBS volume, change EBS to different instances.
4. Stand up an NFS instance and mount onto a server.

